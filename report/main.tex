% IEEE Double-Column Project Report
% Compile: pdflatex main.tex -> bibtex main -> pdflatex main.tex -> pdflatex main.tex

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage[numbers]{natbib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{booktabs}
\usepackage{listings}

\lstset{
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
  captionpos=b
}

\begin{document}

\title{Project 9: Intelligent Property Price Prediction and\\Agentic Real Estate Advisory System}

\author{
\IEEEauthorblockN{Namangupta}
\IEEEauthorblockA{AI/ML Project Report}
}

\maketitle

\begin{abstract}
This report presents Milestone 1 of an intelligent real-estate analytics system that predicts residential property prices from historical data and provides structured advisory signals for buyers and investors. The implementation compares Linear Regression, Decision Tree, and Random Forest models on the Kaggle Housing Prices dataset, evaluates them using MAE, RMSE, and $R^2$, and exposes predictions through a Streamlit user interface. Experimental results show that Linear Regression achieves the best RMSE among tested models, and the system is packaged for free-tier public deployment.
\end{abstract}

\begin{IEEEkeywords}
Real estate analytics, property price prediction, regression, explainable AI, Streamlit.
\end{IEEEkeywords}

\section{Introduction}
Property valuation is a high-impact decision point for both home buyers and real-estate investors. Manual valuation is often slow and inconsistent across neighborhoods, while listings can be influenced by non-fundamental factors. This project addresses that gap by building a machine learning pipeline that estimates market price from structured property attributes and surfaces model-driven insights in an accessible web interface.

The long-term objective (Milestone 2) is an agentic advisory layer that transforms predictions into actionable investment recommendations. This report focuses on Milestone 1 deliverables: supervised regression, feature processing, evaluation, and UI-based inference.

\section{Related Work}
Classical regression methods remain strong baselines in tabular real-estate tasks due to interpretability and low computational cost. Ensemble tree methods such as Random Forest are commonly used to model non-linear interactions and mixed feature distributions. Prior benchmarking work and platform references (scikit-learn, Kaggle) motivate the model set selected in this project \cite{scikit,breiman2001,kaggle}.

\section{Methodology}
\subsection{Dataset Description}
The system uses the Kaggle \texttt{Housing.csv} dataset (545 rows, 13 columns), including structural and neighborhood-related attributes such as area, bedrooms, bathrooms, stories, parking, road access, and furnishing status. The prediction target is \texttt{price}.

\subsection{Input--Output Specification}
\textbf{Input (training):} CSV file with historical property records and a numeric target column (\texttt{price}), including location, size, rooms, age/amenity, and optional market indicators.

\textbf{Input (inference):} CSV file with property feature columns (target optional/not required).

\textbf{Output:} Predicted property price for each row, model performance metrics (MAE, RMSE, $R^2$), and key price-driving features.

\subsection{System Architecture (ML Pipeline)}
\begin{lstlisting}[language={}]
Historical CSV -> Preprocessing
               -> Feature Encoding
               -> Train/Test Split
               -> Model Training (LR/DT/RF)
               -> Evaluation (MAE, RMSE, R2)
               -> Artifact Save (joblib + metadata)

New Property CSV -> Load Trained Artifact
                 -> Inference
                 -> Predicted Price + Downloadable CSV
\end{lstlisting}

\subsection{Preprocessing}
The following transformations are applied:
\begin{itemize}
    \item Missing-value handling (drop null rows in the notebook baseline).
    \item Binary mapping for yes/no columns (e.g., \texttt{mainroad}, \texttt{guestroom}, \texttt{basement}, \texttt{airconditioning}, \texttt{prefarea}).
    \item One-hot encoding of \texttt{furnishingstatus} with drop-first strategy.
\end{itemize}

\subsection{Feature Engineering}
Model input features are:
\texttt{area, bedrooms, guestroom, bathrooms, mainroad, prefarea, stories, parking, basement, airconditioning, furnishingstatus\_semi-furnished, furnishingstatus\_unfurnished}.

\subsection{Models Used}
Three supervised regressors are trained and compared:
\begin{itemize}
    \item Linear Regression
    \item Decision Tree Regressor
    \item Random Forest Regressor (200 trees)
\end{itemize}

\subsection{Training and Validation}
A train-test split of 80:20 with \texttt{random\_state=42} is used. Model quality is evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and coefficient of determination ($R^2$).

\section{Results}
\subsection{Quantitative Results}
\begin{table}[ht]
\centering
\caption{Model Performance Comparison (Test Set)}
\begin{tabular}{lccc}
\toprule
Model & MAE & RMSE & $R^2$ \\
\midrule
Linear Regression & 994646.79 & \textbf{1347778.29} & \textbf{0.6406} \\
Decision Tree & 1281032.11 & 1754528.50 & 0.3910 \\
Random Forest & 1035929.00 & 1409390.67 & 0.6070 \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{table}

Based on RMSE minimization, Linear Regression is selected as the best model in the baseline notebook. A sample inference generated an estimated price of 6,212,951.5 for a test input configuration.

\subsection{System Output and Explainability}
The implemented Streamlit application supports:
\begin{itemize}
    \item CSV upload for training and inference,
    \item model selection and metric display,
    \item feature-importance visualization (for tree models),
    \item downloadable prediction outputs.
\end{itemize}

\section{Discussion}
The baseline demonstrates that even simple regression can produce useful valuation signals on structured housing features. The Linear Regression model outperformed tree-based methods on this dataset split, suggesting either near-linear relationships or limited gains from non-linear partitioning at current data scale.

Limitations include single split evaluation, potential geographic distribution shift, and absence of temporal macroeconomic indicators. For production-grade reliability, k-fold cross-validation, calibration checks, and out-of-domain detection should be added.

\section{Conclusion}
Milestone 1 requirements are satisfied with a complete ML workflow, comparative regression evaluation, and a functional UI for prediction and interpretation. The next step is Milestone 2: adding an agentic recommendation layer (e.g., LangGraph + open-source/free-tier LLM) that combines predicted value, user budget, risk preference, and market context into structured buy/hold/skip guidance.

\bibliographystyle{IEEEtranN}
\bibliography{references}

\appendix
\section{GitHub Repository Information}

\subsection{Repository Link}
\begin{center}
\textbf{\url{https://github.com/gnaman734/housing-prices}}
\end{center}

\subsection{Public Deployment Link}
\begin{center}
\textbf{\url{https://<add-your-streamlit-or-hf-space-url>}}
\end{center}

\subsection{Repository Structure}
\begin{lstlisting}[language={}]
New project/
|- app.py
|- requirements.txt
|- README.md
|- data/
|  |- sample_property_data.csv
|- notebooks/
|  |- notebook778e406a1b.ipynb
|- src/
|  |- modeling.py
|  |- io_utils.py
|- report/
|  |- main.tex
|  |- references.bib
\end{lstlisting}

\subsection{Description of Key Components}
\begin{itemize}
    \item \textbf{app.py}: Streamlit user interface for training, prediction, and advisory output.
    \item \textbf{src/}: Modular ML pipeline and model artifact utilities.
    \item \textbf{notebooks/}: Source Kaggle notebook used as baseline experiment.
    \item \textbf{report/}: IEEE-style project report source files.
\end{itemize}

\end{document}
